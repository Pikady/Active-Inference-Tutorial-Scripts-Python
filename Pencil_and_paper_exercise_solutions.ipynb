{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#-- Code/solutions for pencil and paper exercises --\n",
    "####################################################\n",
    "\n",
    "# Supplementary Code for: A Step-by-Step Tutorial on Active Inference Modelling and its \n",
    "# Application to Empirical Data\n",
    "\n",
    "# By: Ryan Smith, Karl J. Friston, Christopher J. Whyte\n",
    "\n",
    "# Note to readers: be sure to run sections individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural log that replaces zero values with very small values for numerical reasons.\n",
    "def nat_log(x):\n",
    "    x = np.where(x == 0, 1e-16, x)\n",
    "    return np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior over states q(s):\n",
      " \n",
      "[0.92307692 0.07692308]\n"
     ]
    }
   ],
   "source": [
    "# priors\n",
    "D = np.array([0.75, 0.25])\n",
    "\n",
    "# likelihood mapping\n",
    "A = np.array([[0.8, 0.2],\n",
    "              [0.2, 0.8]])\n",
    "\n",
    "# observations\n",
    "o = np.array([1, 0])\n",
    "\n",
    "# express generative model in terms of update equations\n",
    "lns = nat_log(D) + nat_log(A.T @ o)\n",
    "\n",
    "# normalize using a softmax function to find posterior\n",
    "s = np.exp(lns) / np.sum(np.exp(lns))\n",
    "\n",
    "print('Posterior over states q(s):')\n",
    "print(' ')\n",
    "print(s)\n",
    "\n",
    "# Note: Because the natural log of 0 is undefined, for numerical reasons \n",
    "# the nat_log function here replaces zero values with very small values. This\n",
    "# means that the answers generated by this function will vary slightly from\n",
    "# the exact solutions shown in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final posterior beliefs over states:\n",
      "[[0.93971712 0.97262824]\n",
      " [0.06028288 0.02737176]]\n"
     ]
    }
   ],
   "source": [
    "# priors\n",
    "D = np.array([0.5, 0.5])\n",
    "\n",
    "# likelihood mapping\n",
    "A = np.array([[0.9, 0.1],\n",
    "              [0.1, 0.9]])\n",
    "\n",
    "# transitions\n",
    "B = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# observations  \n",
    "o = {\n",
    "    (1, 1): np.array([1, 0]),\n",
    "    (1, 2): np.array([0, 0]),\n",
    "    (2, 1): np.array([1, 0]),\n",
    "    (2, 2): np.array([1, 0])\n",
    "}\n",
    "\n",
    "# number of timesteps\n",
    "T = 2\n",
    "\n",
    "# initialise posterior \n",
    "Qs = np.zeros((2, T))  # 创建一个 2xT 的零矩阵\n",
    "for t in range(T):\n",
    "    Qs[:, t] = np.array([0.5, 0.5])\n",
    "\n",
    "for t in range(T):\n",
    "    for tau in range(1, T + 1):\n",
    "        # get correct D and B for each time point\n",
    "        if tau == 1:  # first time point\n",
    "            lnD = nat_log(D)  # past\n",
    "            lnBs = nat_log(B.T @ Qs[:, tau])  # future\n",
    "        elif tau == T:  # last time point\n",
    "            lnBs = nat_log(B.T @ Qs[:, tau - 2])  # no contribution from future\n",
    "\n",
    "        # likelihood\n",
    "        lnAo = nat_log(A.T @ o[(t + 1, tau)])\n",
    "\n",
    "        # update equation\n",
    "        if tau == 1:\n",
    "            lns = 0.5 * lnD + 0.5 * lnBs + lnAo\n",
    "        elif tau == T:\n",
    "            lns = 0.5 * lnBs + lnAo\n",
    "\n",
    "        # normalize using a softmax function to find posterior\n",
    "        Qs[:, tau - 1] = np.exp(lns) / np.sum(np.exp(lns))\n",
    "\n",
    "print('Final posterior beliefs over states:')\n",
    "print(Qs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch",
   "language": "python",
   "name": "learnpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
