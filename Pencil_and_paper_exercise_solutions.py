####################################################
#-- Code/solutions for pencil and paper exercises --
####################################################

# Supplementary Code for: A Step-by-Step Tutorial on Active Inference Modelling and its 
# Application to Empirical Data

# By: Ryan Smith, Karl J. Friston, Christopher J. Whyte

# Note to readers: be sure to run sections individually

import numpy as np

# Static perception
# priors
D = np.array([0.75, 0.25])

# likelihood mapping
A = np.array([[0.8, 0.2],
              [0.2, 0.8]])

# observations
o = np.array([1, 0])

# express generative model in terms of update equations
lns = np.log(D) + np.log(A.T @ o)

# normalize using a softmax function to find posterior
s = np.exp(lns) / np.sum(np.exp(lns))

print('Posterior over states q(s):')
print(' ')
print(s)

# Note: Because the natural log of 0 is undefined, for numerical reasons 
# the nat_log function here replaces zero values with very small values. This
# means that the answers generated by this function will vary slightly from
# the exact solutions shown in the text.